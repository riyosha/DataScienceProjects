{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is adapted from the assignment prompt provided in Coursera's course - NLP with Probabilistic Models.\n",
    "It is based on the autocorrect model propsed by Peter Norvig in 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract words from a text file\n",
    "def process_data(text_file):\n",
    "    with open(text_file, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    content=content.lower()\n",
    "    vocab = re.findall('\\w+',content)\n",
    "\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
      "There are 6116 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "word_l = process_data('shakespeare.txt')\n",
    "vocab = set(word_l) \n",
    "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")\n",
    "\n",
    "\n",
    "#process data works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn to create dictionary tracking frequency of words \n",
    "def get_count(word_l):\n",
    "    vocab = set(word_l)\n",
    "    ans=dict()\n",
    "    for word in word_l:\n",
    "        if word in ans.keys():\n",
    "            ans[word]+=1\n",
    "        else:\n",
    "            ans[word]=1\n",
    "    \n",
    "    return ans\n",
    "\n",
    "#fn to create dictionary with word probabilities\n",
    "def get_probs(word_l):\n",
    "    count = get_count(word_l)\n",
    "    n = len(word_l)\n",
    "    return {k: v/n for k, v in count.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit functions - these functions return a list of possible words after replacing, inserting, deleting or switching letters\n",
    "# only valid words that are a part of the text we have trained on are returned\n",
    "\n",
    "def delete_letter(word, verbose=False):\n",
    "    n=len(word)\n",
    "    ans=[word[:i]+word[i+1:] for i in range(n)]\n",
    "    splits = [(word[:i],word[i:]) for i in range(n)]\n",
    "\n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {splits}, \\ndelete_l = {ans}\")\n",
    "\n",
    "    return ans\n",
    "\n",
    "def switch_letter(word, verbose=False):\n",
    "\n",
    "    n = len(word)\n",
    "    ans=[word[:i-1]+word[i]+word[i-1]+word[i+1:] for i in range(1,n)]\n",
    "    splits = [(word[:i],word[i:]) for i in range(n)]\n",
    "\n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {splits}, \\ndelete_l = {ans}\")\n",
    "\n",
    "    return ans\n",
    "\n",
    "def replace_letter(word,verbose=False):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    n=len(word)\n",
    "    ans = [word[:i]+letter+word[i+1:] for i in range(n) for letter in letters if letter != word[i]]\n",
    "    splits = [(word[:i],word[i:]) for i in range(n)]\n",
    "\n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {splits}, \\ndelete_l = {ans}\")\n",
    "\n",
    "    return ans\n",
    "\n",
    "def insert_letter(word,verbose=False):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    n=len(word)\n",
    "    ans = [word[:i]+letter+word[i:] for i in range(n) for letter in letters]\n",
    "    ans = ans + [word+letter for letter in letters]\n",
    "    splits = [(word[:i],word[i:]) for i in range(n)]\n",
    "\n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {splits}, \\ndelete_l = {ans}\")\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fns that return list of possible correct words after editing one letter or two letters at most\n",
    "# words are returned in decreasing order of their probabilities\n",
    "\n",
    "def edit_one_letter(word, vocab):\n",
    "    ans = set()\n",
    "\n",
    "    for word in replace_letter(word)+switch_letter(word)+insert_letter(word)+delete_letter(word):\n",
    "        if word in vocab:\n",
    "            ans.add(word)\n",
    "    \n",
    "    return ans\n",
    "\n",
    "def edit_two_letter(word,vocab):\n",
    "    \n",
    "    first_edit= edit_one_letter(word,vocab)\n",
    "    ans=set()\n",
    "    for w in first_edit:\n",
    "        ans = ans|edit_one_letter(w,vocab)\n",
    "    \n",
    "    return ans\n",
    "\n",
    "def get_corrections(word, vocab,prob_dict,n=2, verbose = False):\n",
    "    one_letter = edit_one_letter(word,vocab)\n",
    "    two_letter = edit_two_letter(word,vocab)\n",
    "\n",
    "    if word in vocab:\n",
    "        # if word is correct, same returned\n",
    "        return f'{word} is correct'\n",
    "    #if candidates with one edit exist, candidates with 2 edits won't be considered, as one letter mistakes are more likely than 2 letter mistakes\n",
    "    elif one_letter:\n",
    "        suggestions = set(sorted(one_letter, key=lambda word: prob_dict.get(word, float('-inf')), reverse=True)[:n])\n",
    "        k = len(suggestions)\n",
    "        if k<n:\n",
    "            #in case n one edit suggestions don't exist, the remaining ones will be given by 2 edits\n",
    "            suggestions = suggestions | set(sorted(two_letter, key=lambda word: prob_dict.get(word, float('-inf')), reverse=True)[:n-k])\n",
    "        return suggestions\n",
    "    elif two_letter:\n",
    "        return set(sorted(two_letter, key=lambda word: prob_dict.get(word, float('-inf')), reverse=True)[:n])\n",
    "    else:\n",
    "\n",
    "        return f'Sorry, no words like {word} exist in the given training set'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, test the autocorrect function yourself!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrect suggestions:  never is correct\n"
     ]
    }
   ],
   "source": [
    "#Test implementation\n",
    "your_word = re.sub(r'[^a-z]', '', input('Enter word: ').lower())\n",
    "n = int(input('Number of suggestions desired: ')) \n",
    "prob_dict=get_probs(word_l)\n",
    "tmp_corrections = get_corrections(your_word, vocab, prob_dict, n, verbose=True) # keep verbose=True\n",
    "print('Autocorrect suggestions: ', tmp_corrections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the following function can be used to find the min edit distance between two words using dynamic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source,target):\n",
    "\n",
    "    m=len(source)+1\n",
    "    n = len(target)+1\n",
    "    dp_table = [[[0] for i in range(n)] for j in range(m)]\n",
    "\n",
    "    for i in range(m):\n",
    "        dp_table[i][0]=i\n",
    "    for i in range(1,n):\n",
    "        dp_table[0][i]=i\n",
    "    \n",
    "    for i in range(1,m):\n",
    "        for j in range(1,n):\n",
    "            switched=0\n",
    "            #cost to replace letters\n",
    "            if source[i-1] == target[j-1]:\n",
    "                replace_cost=0\n",
    "            else:\n",
    "                replace_cost=1\n",
    "            \n",
    "            if i<m-1 and j<n-1:\n",
    "                #cost to switch letters\n",
    "                if (source[i-1] , source[i] == target[j], target[j-1]):\n",
    "                    switch_cost = 1\n",
    "                    switched = 1\n",
    "                else:\n",
    "                    switch_cost = float(inf)\n",
    "                \n",
    "                if switched ==0:\n",
    "                    dp_table[i][j]=min([dp_table[i-1][j]+1, dp_table[i-1][j]+1, dp_table[i-1][j-1]+replace_cost,dp_table[i-1][j-1]+switch_cost])\n",
    "                else:\n",
    "                    dp_table[i][j]=min([dp_table[i-1][j]+1, dp_table[i-1][j]+1, dp_table[i-1][j-1]+replace_cost,dp_table[i-1][j-1]])\n",
    "                    switched=0\n",
    "            else:\n",
    "                dp_table[i][j]=min([dp_table[i-1][j]+1, dp_table[i-1][j]+1, dp_table[i-1][j-1]+replace_cost])\n",
    "\n",
    "    \n",
    "    return dp_table[-1][-1], dp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " [[0, 1, 2, 3, 4, 5],\n",
       "  [1, 0, 1, 2, 3, 5],\n",
       "  [2, 1, 0, 1, 2, 4],\n",
       "  [3, 2, 1, 0, 1, 3],\n",
       "  [4, 3, 2, 1, 0, 2],\n",
       "  [5, 4, 3, 2, 1, 1],\n",
       "  [6, 5, 4, 3, 2, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_edit_distance('othger','other')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
