{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "\n",
    "from utils import (cosine_similarity, get_dict)\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to download all required data was taken from Coursera \n",
    "https://github.com/amanchadha/coursera-natural-language-processing-specialization/blob/master/1%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/Week%204/C1W4_A1_Word%20Translation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0  599M    0 34068    0     0  18805      0  9:17:14  0:00:01  9:17:13 18968\n",
      "  0  599M    0  100k    0     0  36585      0  4:46:25  0:00:02  4:46:23 36788\n",
      "  0  599M    0 2696k    0     0   714k      0  0:14:18  0:00:03  0:14:15  718k\n",
      "  1  599M    1 7480k    0     0  1567k      0  0:06:31  0:00:04  0:06:27 1572k\n",
      "  1  599M    1 11.7M    0     0  2083k      0  0:04:54  0:00:05  0:04:49 2714k\n",
      "  2  599M    2 16.0M    0     0  2428k      0  0:04:12  0:00:06  0:04:06 3307k\n",
      "  3  599M    3 20.0M    0     0  2646k      0  0:03:52  0:00:07  0:03:45 4120k\n",
      "  4  599M    4 24.8M    0     0  2896k      0  0:03:31  0:00:08  0:03:23 4541k\n",
      "  4  599M    4 29.4M    0     0  3085k      0  0:03:18  0:00:09  0:03:09 4533k\n",
      "  5  599M    5 34.1M    0     0  3244k      0  0:03:09  0:00:10  0:02:59 4592k\n",
      "  6  599M    6 38.3M    0     0  3339k      0  0:03:03  0:00:11  0:02:52 4575k\n",
      "  7  599M    7 42.3M    0     0  3388k      0  0:03:01  0:00:12  0:02:49 4538k\n",
      "  7  599M    7 45.0M    0     0  3347k      0  0:03:03  0:00:13  0:02:50 4140k\n",
      "  8  599M    8 48.3M    0     0  3349k      0  0:03:03  0:00:14  0:02:49 3864k\n",
      "  8  599M    8 51.5M    0     0  3346k      0  0:03:03  0:00:15  0:02:48 3566k\n",
      "  9  599M    9 55.0M    0     0  3358k      0  0:03:02  0:00:16  0:02:46 3404k\n",
      "  9  599M    9 57.7M    0     0  3325k      0  0:03:04  0:00:17  0:02:47 3162k\n",
      " 10  599M   10 60.5M    0     0  3299k      0  0:03:06  0:00:18  0:02:48 3166k\n",
      " 10  599M   10 63.8M    0     0  3305k      0  0:03:05  0:00:19  0:02:46 3175k\n",
      " 11  599M   11 68.1M    0     0  3356k      0  0:03:02  0:00:20  0:02:42 3387k\n",
      " 11  599M   11 70.5M    0     0  3302k      0  0:03:05  0:00:21  0:02:44 3117k\n",
      " 12  599M   12 74.6M    0     0  3345k      0  0:03:03  0:00:22  0:02:41 3415k\n",
      " 12  599M   12 76.6M    0     0  3292k      0  0:03:06  0:00:23  0:02:43 3264k\n",
      " 13  599M   13 81.5M    0     0  3371k      0  0:03:02  0:00:24  0:02:38 3632k\n",
      " 14  599M   14 85.5M    0     0  3400k      0  0:03:00  0:00:25  0:02:35 3580k\n",
      " 15  599M   15 90.3M    0     0  3454k      0  0:02:57  0:00:26  0:02:31 4128k\n",
      " 15  599M   15 95.3M    0     0  3506k      0  0:02:55  0:00:27  0:02:28 4244k\n",
      " 16  599M   16 97.9M    0     0  3468k      0  0:02:57  0:00:28  0:02:29 4294k\n",
      " 16  599M   16  100M    0     0  3467k      0  0:02:57  0:00:29  0:02:28 3940k\n",
      " 17  599M   17  104M    0     0  3400k      0  0:03:00  0:00:31  0:02:29 3399k\n",
      " 17  599M   17  104M    0     0  3294k      0  0:03:06  0:00:32  0:02:34 2534k\n",
      " 17  599M   17  104M    0     0  3195k      0  0:03:12  0:00:33  0:02:39 1642k\n",
      " 17  599M   17  104M    0     0  3101k      0  0:03:17  0:00:34  0:02:43 1180k\n",
      " 17  599M   17  104M    0     0  3063k      0  0:03:20  0:00:34  0:02:46  704k\n",
      " 17  599M   17  107M    0     0  3067k      0  0:03:20  0:00:35  0:02:45  674k\n",
      " 18  599M   18  110M    0     0  3070k      0  0:03:19  0:00:36  0:02:43 1411k\n",
      " 19  599M   19  114M    0     0  3079k      0  0:03:19  0:00:38  0:02:41 2244k\n",
      " 19  599M   19  117M    0     0  3093k      0  0:03:18  0:00:38  0:02:40 3026k\n",
      " 20  599M   20  121M    0     0  3115k      0  0:03:17  0:00:39  0:02:38 3478k\n",
      " 20  599M   20  122M    0     0  3086k      0  0:03:18  0:00:40  0:02:38 3219k\n",
      " 20  599M   20  125M    0     0  3068k      0  0:03:20  0:00:41  0:02:39 3053k\n",
      " 21  599M   21  128M    0     0  3075k      0  0:03:19  0:00:42  0:02:37 3042k\n",
      " 21  599M   21  131M    0     0  3080k      0  0:03:19  0:00:43  0:02:36 2983k\n",
      " 22  599M   22  135M    0     0  3106k      0  0:03:17  0:00:44  0:02:33 3036k\n",
      " 23  599M   23  139M    0     0  3121k      0  0:03:16  0:00:45  0:02:31 3408k\n",
      " 24  599M   24  144M    0     0  3162k      0  0:03:14  0:00:46  0:02:28 3950k\n",
      " 24  599M   24  148M    0     0  3192k      0  0:03:12  0:00:47  0:02:25 4201k\n",
      " 25  599M   25  153M    0     0  3216k      0  0:03:10  0:00:48  0:02:22 4394k\n",
      " 26  599M   26  157M    0     0  3238k      0  0:03:09  0:00:49  0:02:20 4423k\n",
      " 27  599M   27  161M    0     0  3266k      0  0:03:07  0:00:50  0:02:17 4595k\n",
      " 27  599M   27  166M    0     0  3296k      0  0:03:06  0:00:51  0:02:15 4552k\n",
      " 28  599M   28  171M    0     0  3335k      0  0:03:04  0:00:52  0:02:12 4699k\n",
      " 29  599M   29  176M    0     0  3365k      0  0:03:02  0:00:53  0:02:09 4831k\n",
      " 30  599M   30  182M    0     0  3407k      0  0:03:00  0:00:54  0:02:06 5089k\n",
      " 31  599M   31  188M    0     0  3452k      0  0:02:57  0:00:55  0:02:02 5344k\n",
      " 32  599M   32  193M    0     0  3491k      0  0:02:55  0:00:56  0:01:59 5507k\n",
      " 33  599M   33  199M    0     0  3534k      0  0:02:53  0:00:57  0:01:56 5638k\n",
      " 34  599M   34  204M    0     0  3569k      0  0:02:52  0:00:58  0:01:54 5760k\n",
      " 34  599M   34  209M    0     0  3590k      0  0:02:51  0:00:59  0:01:52 5589k\n",
      " 35  599M   35  213M    0     0  3594k      0  0:02:50  0:01:00  0:01:50 5175k\n",
      " 36  599M   36  218M    0     0  3627k      0  0:02:49  0:01:01  0:01:48 5177k\n",
      " 37  599M   37  223M    0     0  3653k      0  0:02:48  0:01:02  0:01:46 5023k\n",
      " 38  599M   38  229M    0     0  3688k      0  0:02:46  0:01:03  0:01:43 5097k\n",
      " 39  599M   39  234M    0     0  3710k      0  0:02:45  0:01:04  0:01:41 5145k\n",
      " 40  599M   40  240M    0     0  3750k      0  0:02:43  0:01:05  0:01:38 5646k\n",
      " 41  599M   41  246M    0     0  3775k      0  0:02:42  0:01:06  0:01:36 5603k\n",
      " 41  599M   41  250M    0     0  3778k      0  0:02:42  0:01:07  0:01:35 5355k\n",
      " 42  599M   42  254M    0     0  3793k      0  0:02:41  0:01:08  0:01:33 5132k\n",
      " 43  599M   43  260M    0     0  3818k      0  0:02:40  0:01:09  0:01:31 5217k\n",
      " 43  599M   43  262M    0     0  3800k      0  0:02:41  0:01:10  0:01:31 4451k\n",
      " 44  599M   44  268M    0     0  3824k      0  0:02:40  0:01:11  0:01:29 4474k\n",
      " 45  599M   45  274M    0     0  3849k      0  0:02:39  0:01:12  0:01:27 4784k\n",
      " 46  599M   46  279M    0     0  3876k      0  0:02:38  0:01:13  0:01:25 5012k\n",
      " 47  599M   47  284M    0     0  3895k      0  0:02:37  0:01:14  0:01:23 4969k\n",
      " 48  599M   48  288M    0     0  3892k      0  0:02:37  0:01:15  0:01:22 5193k\n",
      " 49  599M   49  294M    0     0  3926k      0  0:02:36  0:01:16  0:01:20 5385k\n",
      " 49  599M   49  299M    0     0  3933k      0  0:02:36  0:01:17  0:01:19 5160k\n",
      " 50  599M   50  302M    0     0  3935k      0  0:02:35  0:01:18  0:01:17 4814k\n",
      " 51  599M   51  307M    0     0  3947k      0  0:02:35  0:01:19  0:01:16 4720k\n",
      " 52  599M   52  313M    0     0  3977k      0  0:02:34  0:01:20  0:01:14 5275k\n",
      " 53  599M   53  318M    0     0  3994k      0  0:02:33  0:01:21  0:01:12 5040k\n",
      " 54  599M   54  324M    0     0  4010k      0  0:02:33  0:01:22  0:01:11 5240k\n",
      " 55  599M   55  329M    0     0  4032k      0  0:02:32  0:01:23  0:01:09 5549k\n",
      " 56  599M   56  336M    0     0  4062k      0  0:02:31  0:01:24  0:01:07 5919k\n",
      " 56  599M   56  340M    0     0  4062k      0  0:02:31  0:01:25  0:01:06 5416k\n",
      " 57  599M   57  345M    0     0  4073k      0  0:02:30  0:01:26  0:01:04 5363k\n",
      " 58  599M   58  350M    0     0  4082k      0  0:02:30  0:01:27  0:01:03 5253k\n",
      " 58  599M   58  352M    0     0  4071k      0  0:02:30  0:01:28  0:01:02 4724k\n",
      " 59  599M   59  356M    0     0  4060k      0  0:02:31  0:01:29  0:01:02 4025k\n",
      " 60  599M   60  360M    0     0  4063k      0  0:02:31  0:01:30  0:01:01 4080k\n",
      " 60  599M   60  365M    0     0  4073k      0  0:02:30  0:01:31  0:00:59 4089k\n",
      " 61  599M   61  368M    0     0  4064k      0  0:02:31  0:01:32  0:00:59 3728k\n",
      " 62  599M   62  372M    0     0  4056k      0  0:02:31  0:01:33  0:00:58 3806k\n",
      " 62  599M   62  375M    0     0  4052k      0  0:02:31  0:01:34  0:00:57 3912k\n",
      " 63  599M   63  379M    0     0  4060k      0  0:02:31  0:01:35  0:00:56 3995k\n",
      " 64  599M   64  384M    0     0  4066k      0  0:02:30  0:01:36  0:00:54 3936k\n",
      " 64  599M   64  388M    0     0  4069k      0  0:02:30  0:01:37  0:00:53 4171k\n",
      " 65  599M   65  392M    0     0  4067k      0  0:02:30  0:01:38  0:00:52 4272k\n",
      " 66  599M   66  396M    0     0  4067k      0  0:02:30  0:01:39  0:00:51 4339k\n",
      " 66  599M   66  399M    0     0  4064k      0  0:02:31  0:01:40  0:00:51 4138k\n",
      " 67  599M   67  404M    0     0  4068k      0  0:02:30  0:01:41  0:00:49 4107k\n",
      " 68  599M   68  408M    0     0  4065k      0  0:02:31  0:01:42  0:00:49 3979k\n",
      " 68  599M   68  411M    0     0  4061k      0  0:02:31  0:01:43  0:00:48 3934k\n",
      " 69  599M   69  415M    0     0  4056k      0  0:02:31  0:01:44  0:00:47 3850k\n",
      " 69  599M   69  417M    0     0  4040k      0  0:02:31  0:01:45  0:00:46 3552k\n",
      " 70  599M   70  421M    0     0  4041k      0  0:02:31  0:01:46  0:00:45 3486k\n",
      " 71  599M   71  425M    0     0  4042k      0  0:02:31  0:01:47  0:00:44 3577k\n",
      " 71  599M   71  429M    0     0  4046k      0  0:02:31  0:01:48  0:00:43 3732k\n",
      " 72  599M   72  433M    0     0  4048k      0  0:02:31  0:01:49  0:00:42 3872k\n",
      " 73  599M   73  439M    0     0  4058k      0  0:02:31  0:01:50  0:00:41 4443k\n",
      " 73  599M   73  442M    0     0  4054k      0  0:02:31  0:01:51  0:00:40 4337k\n",
      " 74  599M   74  445M    0     0  4048k      0  0:02:31  0:01:52  0:00:39 4167k\n",
      " 75  599M   75  449M    0     0  4044k      0  0:02:31  0:01:53  0:00:38 4003k\n",
      " 75  599M   75  452M    0     0  4035k      0  0:02:32  0:01:54  0:00:38 3759k\n",
      " 75  599M   75  455M    0     0  4025k      0  0:02:32  0:01:55  0:00:37 3316k\n",
      " 76  599M   76  458M    0     0  4016k      0  0:02:32  0:01:56  0:00:36 3147k\n",
      " 76  599M   76  461M    0     0  4005k      0  0:02:33  0:01:57  0:00:36 3079k\n",
      " 77  599M   77  465M    0     0  4011k      0  0:02:33  0:01:58  0:00:35 3236k\n",
      " 78  599M   78  468M    0     0  4003k      0  0:02:33  0:01:59  0:00:34 3260k\n",
      " 78  599M   78  471M    0     0  3999k      0  0:02:33  0:02:00  0:00:33 3381k\n",
      " 79  599M   79  475M    0     0  3996k      0  0:02:33  0:02:01  0:00:32 3531k\n",
      " 79  599M   79  478M    0     0  3991k      0  0:02:33  0:02:02  0:00:31 3647k\n",
      " 80  599M   80  481M    0     0  3985k      0  0:02:34  0:02:03  0:00:31 3379k\n",
      " 80  599M   80  485M    0     0  3982k      0  0:02:34  0:02:04  0:00:30 3472k\n",
      " 81  599M   81  489M    0     0  3988k      0  0:02:33  0:02:05  0:00:28 3721k\n",
      " 82  599M   82  493M    0     0  3984k      0  0:02:34  0:02:06  0:00:28 3698k\n",
      " 82  599M   82  497M    0     0  3984k      0  0:02:34  0:02:07  0:00:27 3805k\n",
      " 83  599M   83  500M    0     0  3976k      0  0:02:34  0:02:08  0:00:26 3756k\n",
      " 84  599M   84  504M    0     0  3977k      0  0:02:34  0:02:09  0:00:25 3844k\n",
      " 84  599M   84  508M    0     0  3979k      0  0:02:34  0:02:10  0:00:24 3745k\n",
      " 85  599M   85  512M    0     0  3981k      0  0:02:34  0:02:11  0:00:23 3886k\n",
      " 86  599M   86  515M    0     0  3968k      0  0:02:34  0:02:13  0:00:21 3595k\n",
      " 86  599M   86  519M    0     0  3975k      0  0:02:34  0:02:13  0:00:21 3952k\n",
      " 87  599M   87  523M    0     0  3977k      0  0:02:34  0:02:14  0:00:20 3979k\n",
      " 87  599M   87  527M    0     0  3973k      0  0:02:34  0:02:15  0:00:19 3820k\n",
      " 88  599M   88  531M    0     0  3976k      0  0:02:34  0:02:16  0:00:18 3866k\n",
      " 88  599M   88  533M    0     0  3962k      0  0:02:34  0:02:17  0:00:17 3795k\n",
      " 89  599M   89  535M    0     0  3952k      0  0:02:35  0:02:18  0:00:17 3344k\n",
      " 89  599M   89  537M    0     0  3931k      0  0:02:36  0:02:19  0:00:17 2750k\n",
      " 89  599M   89  539M    0     0  3923k      0  0:02:36  0:02:20  0:00:16 2541k\n",
      " 90  599M   90  542M    0     0  3919k      0  0:02:36  0:02:21  0:00:15 2365k\n",
      " 90  599M   90  544M    0     0  3903k      0  0:02:37  0:02:22  0:00:15 2255k\n",
      " 91  599M   91  546M    0     0  3894k      0  0:02:37  0:02:23  0:00:14 2268k\n",
      " 91  599M   91  549M    0     0  3889k      0  0:02:37  0:02:24  0:00:13 2643k\n",
      " 92  599M   92  553M    0     0  3885k      0  0:02:38  0:02:25  0:00:13 2829k\n",
      " 92  599M   92  556M    0     0  3879k      0  0:02:38  0:02:26  0:00:12 2731k\n",
      " 93  599M   93  559M    0     0  3875k      0  0:02:38  0:02:27  0:00:11 3082k\n",
      " 93  599M   93  562M    0     0  3869k      0  0:02:38  0:02:28  0:00:10 3132k\n",
      " 94  599M   94  565M    0     0  3865k      0  0:02:38  0:02:29  0:00:09 3197k\n",
      " 94  599M   94  567M    0     0  3856k      0  0:02:39  0:02:30  0:00:09 3001k\n",
      " 95  599M   95  569M    0     0  3845k      0  0:02:39  0:02:31  0:00:08 2850k\n",
      " 95  599M   95  572M    0     0  3838k      0  0:02:39  0:02:32  0:00:07 2717k\n",
      " 95  599M   95  575M    0     0  3832k      0  0:02:40  0:02:33  0:00:07 2730k\n",
      " 96  599M   96  578M    0     0  3824k      0  0:02:40  0:02:34  0:00:06 2574k\n",
      " 97  599M   97  581M    0     0  3823k      0  0:02:40  0:02:35  0:00:05 2828k\n",
      " 97  599M   97  584M    0     0  3820k      0  0:02:40  0:02:36  0:00:04 3061k\n",
      " 97  599M   97  587M    0     0  3811k      0  0:02:41  0:02:37  0:00:04 2989k\n",
      " 98  599M   98  590M    0     0  3805k      0  0:02:41  0:02:38  0:00:03 2987k\n",
      " 98  599M   98  593M    0     0  3801k      0  0:02:41  0:02:39  0:00:02 3096k\n",
      " 99  599M   99  595M    0     0  3795k      0  0:02:41  0:02:40  0:00:01 2905k\n",
      " 99  599M   99  598M    0     0  3789k      0  0:02:42  0:02:41  0:00:01 2813k\n",
      "100  599M  100  599M    0     0  3788k      0  0:02:42  0:02:42 --:--:-- 2960k\n"
     ]
    }
   ],
   "source": [
    "!curl -o ./wiki.multi.fr.vec https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.fr.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add folder, tmp2, from our local workspace containing pre-downloaded corpora files to nltk's data path\n",
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the english to french training dictionary is 5000\n",
      "The length of the english to french test dictionary is 5000\n"
     ]
    }
   ],
   "source": [
    "# Use this code to download and process the full dataset on your local computer\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "en_embeddings = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)\n",
    "fr_embeddings = KeyedVectors.load_word2vec_format('./wiki.multi.fr.vec')\n",
    "\n",
    "english_set = set(en_embeddings.index_to_key)\n",
    "french_set = set(fr_embeddings.index_to_key)\n",
    "en_embeddings_subset = {}\n",
    "fr_embeddings_subset = {}\n",
    "french_words = set(en_fr_train.values())\n",
    "\n",
    "for en_word in en_fr_train.keys():\n",
    "    fr_word = en_fr_train[en_word]\n",
    "    if fr_word in french_set and en_word in english_set:\n",
    "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
    "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
    "\n",
    "\n",
    "for en_word in en_fr_test.keys():\n",
    "    fr_word = en_fr_test[en_word]\n",
    "    if fr_word in french_set and en_word in english_set:\n",
    "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
    "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
    "\n",
    "\n",
    "pickle.dump( en_embeddings_subset, open( \"en_embeddings.p\", \"wb\" ) )\n",
    "pickle.dump( fr_embeddings_subset, open( \"fr_embeddings.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the english to french training dictionary is 5000\n",
      "The length of the english to french test dictionary is 5000\n"
     ]
    }
   ],
   "source": [
    "# loading the english to french dictionaries\n",
    "en_fr_train = get_dict('en-fr.train.txt')\n",
    "print('The length of the english to french training dictionary is', len(en_fr_train))\n",
    "en_fr_test = get_dict('en-fr.test.txt')\n",
    "print('The length of the english to french test dictionary is', len(en_fr_train))\n",
    "en_embeddings_subset = pickle.load(open(\"en_embeddings.p\", \"rb\"))\n",
    "fr_embeddings_subset = pickle.load(open(\"fr_embeddings.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combines all enlish and french vectors into respective matrices\n",
    "def get_matrices(en_fr, french_vecs, english_vecs):\n",
    "    # this provides 2 matrices:\n",
    "    # X: columns are english embeddings\n",
    "    # Y: columns are french embeddings\n",
    "\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    eng_terms = set(english_vecs.keys())\n",
    "    french_terms = set(french_vecs.keys())\n",
    "\n",
    "    for eng, fr in en_fr.items():\n",
    "        if eng in eng_terms and fr in french_terms:\n",
    "            X.append(english_vecs[eng])\n",
    "            Y.append(french_vecs[fr])\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_matrices(en_fr_train,fr_embeddings_subset,en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frobenius loss function\n",
    "def loss_fn(X,R,Y):\n",
    "    A = X@R-Y\n",
    "    sum = 0\n",
    "    m=X.shape[0]\n",
    "    for row in A:\n",
    "        for cell in row:\n",
    "            sum+=cell**2\n",
    "\n",
    "    return sum/m\n",
    "\n",
    "#gradient function\n",
    "def gradient(X,R,Y):\n",
    "\n",
    "    m = X.shape[0]\n",
    "    return 2 * X.T @ (X@R-Y) / m\n",
    "\n",
    "#provides matrix R, a transformation bw the english and french vector space\n",
    "def align_embeddings(X,Y, train_steps = 100, learning_rate = 0.0003):\n",
    "    np.random.seed(30)\n",
    "    \n",
    "    R = np.random.rand(X.shape[1],X.shape[1])\n",
    "    \n",
    "    for i in range(1,train_steps+1):\n",
    "        if i%25==0:\n",
    "            print(f'loss at {i}th iteration is: {loss_fn(X,R,Y)}')\n",
    "        R-= learning_rate * gradient(X,R,Y)\n",
    "    \n",
    "    return R\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9864, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at 25th iteration is: 103.4231890420284\n",
      "loss at 50th iteration is: 27.983561727823485\n",
      "loss at 75th iteration is: 10.14778893904696\n",
      "loss at 100th iteration is: 4.519926914719542\n",
      "loss at 125th iteration is: 2.3942884774312243\n",
      "loss at 150th iteration is: 1.4823453010613057\n",
      "loss at 175th iteration is: 1.0529765592879439\n",
      "loss at 200th iteration is: 0.8364359919468837\n",
      "loss at 225th iteration is: 0.7214002414291245\n",
      "loss at 250th iteration is: 0.6577456329502689\n",
      "loss at 275th iteration is: 0.6213332103227337\n",
      "loss at 300th iteration is: 0.5999129481174299\n",
      "loss at 325th iteration is: 0.5870035746969205\n",
      "loss at 350th iteration is: 0.5790565056333816\n",
      "loss at 375th iteration is: 0.5740715249768429\n",
      "loss at 400th iteration is: 0.5708921566297782\n",
      "loss at 425th iteration is: 0.5688343935218162\n",
      "loss at 450th iteration is: 0.5674852607961616\n",
      "loss at 475th iteration is: 0.5665906961004559\n",
      "loss at 500th iteration is: 0.5659916991397081\n",
      "loss at 525th iteration is: 0.5655872004640026\n",
      "loss at 550th iteration is: 0.5653120446185653\n",
      "loss at 575th iteration is: 0.5651236957944755\n",
      "loss at 600th iteration is: 0.5649940724330358\n",
      "loss at 625th iteration is: 0.5649044516028026\n",
      "loss at 650th iteration is: 0.5648422417849743\n",
      "loss at 675th iteration is: 0.5647989110449096\n",
      "loss at 700th iteration is: 0.5647686404073287\n",
      "loss at 725th iteration is: 0.5647474387857021\n",
      "loss at 750th iteration is: 0.5647325554558992\n",
      "loss at 775th iteration is: 0.564722086595817\n",
      "loss at 800th iteration is: 0.5647147097424615\n",
      "loss at 825th iteration is: 0.5647095033646351\n",
      "loss at 850th iteration is: 0.5647058235441191\n",
      "loss at 875th iteration is: 0.5647032192582532\n",
      "loss at 900th iteration is: 0.56470137392271\n",
      "loss at 925th iteration is: 0.5647000648982735\n",
      "loss at 950th iteration is: 0.564699135348127\n",
      "loss at 975th iteration is: 0.5646984746203653\n",
      "loss at 1000th iteration is: 0.5646980045392318\n"
     ]
    }
   ],
   "source": [
    "R = align_embeddings(X_train,Y_train,train_steps=1000,learning_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nearest_neighbours\n",
    "\n",
    "#naive knn\n",
    "def knn(v,candidates,k=1): # returns indices of the k nearest neighbours\n",
    "    similarities=[]\n",
    "    for u in candidates:\n",
    "        similarities.append(cosine_similarity(v,u))\n",
    "    \n",
    "    return np.argsort(similarities)[-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test accuracy \n",
    "import pandas as pd\n",
    "def test_accuracy(X,R,Y):\n",
    "\n",
    "    pred = X@R\n",
    "    acc=0\n",
    "    n = len(pred)\n",
    "    for i in range(n):\n",
    "        acc+=(i==knn(pred[i],Y)[0])\n",
    "    \n",
    "    return acc/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,Y_test = get_matrices(en_fr_test,fr_embeddings_subset,en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.547287899860918"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(X_test,R,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5539334955393349"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(X_train,R,Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
