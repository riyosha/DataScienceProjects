{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is adapted from Coursera's NLP with Probabilistic Models, Week 2 Assignment\n",
    "Here, we'll implement unidirectional POS tagging with 95% accuracy rate using the Penn Treebank II Tag set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_pos import get_word_tag, preprocess  \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In\\tIN\\n', 'an\\tDT\\n', 'Oct.\\tNNP\\n', '19\\tCD\\n', 'review\\tNN\\n', 'of\\tIN\\n', '``\\t``\\n', 'The\\tDT\\n', 'Misanthrope\\tNN\\n', \"''\\t''\\n\", 'at\\tIN\\n', 'Chicago\\tNNP\\n', \"'s\\tPOS\\n\", 'Goodman\\tNNP\\n', 'Theatre\\tNNP\\n', '(\\t(\\n', '``\\t``\\n', 'Revitalized\\tVBN\\n', 'Classics\\tNNS\\n', 'Take\\tVBP\\n', 'the\\tDT\\n', 'Stage\\tNN\\n', 'in\\tIN\\n', 'Windy\\tNNP\\n', 'City\\tNNP\\n', ',\\t,\\n', \"''\\t''\\n\", 'Leisure\\tNN\\n', '&\\tCC\\n', 'Arts\\tNNS\\n', ')\\t)\\n', ',\\t,\\n', 'the\\tDT\\n', 'role\\tNN\\n', 'of\\tIN\\n', 'Celimene\\tNNP\\n', ',\\t,\\n', 'played\\tVBN\\n', 'by\\tIN\\n', 'Kim\\tNNP\\n', 'Cattrall\\tNNP\\n', ',\\t,\\n', 'was\\tVBD\\n', 'mistakenly\\tRB\\n', 'attributed\\tVBN\\n', 'to\\tTO\\n', 'Christina\\tNNP\\n', 'Haag\\tNNP\\n', '.\\t.\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"WSJ_02-21.pos\", 'r') as f:\n",
    "    training_corpus = f.readlines()\n",
    "    \n",
    "print(training_corpus[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'``\\n', 'VBP\\n', 'IN\\n', 'CC\\n', 'PRP\\n', 'NN\\n', 'JJR\\n', \"''\\n\", 'NNPS\\n', ':\\n', 'TO\\n', 'WP\\n', 'SYM\\n', 'WRB\\n', 'PDT\\n', '.\\n', 'NNS\\n', 'PRP$\\n', 'NNP\\n', 'VBG\\n', 'JJ\\n', ',\\n', 'LS\\n', 'CD\\n', 'POS\\n', '\\n', 'VBZ\\n', 'MD\\n', 'VB\\n', 'JJS\\n', ')\\n', 'EX\\n', '(\\n', 'DT\\n', 'RP\\n', 'WP$\\n', 'FW\\n', 'VBN\\n', '$\\n', 'WDT\\n', 'RB\\n', 'UH\\n', 'RBS\\n', 'VBD\\n', '#\\n', 'RBR\\n'}\n",
      "46\n",
      "989860\n"
     ]
    }
   ],
   "source": [
    "#check how many tags there are \n",
    "def spli_t(string):\n",
    "    try:\n",
    "        return string.split('\\t')[1]\n",
    "    except:\n",
    "        return string\n",
    "\n",
    "tags = set([spli_t(x) for x in training_corpus])\n",
    "print(tags)\n",
    "print(len(tags))\n",
    "print(len(training_corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '#', '$', '%', '&', \"'\", \"''\", \"'40s\", \"'60s\", \"'70s\", \"'80s\", \"'86\", \"'90s\", \"'N\", \"'S\", \"'d\", \"'em\", \"'ll\", \"'m\", \"'n'\", \"'re\", \"'s\", \"'til\", \"'ve\", '(', ')', ',', '-', '--', '--n--', '--unk--', '--unk_adj--', '--unk_adv--', '--unk_digit--', '--unk_noun--', '--unk_punct--', '--unk_upper--', '--unk_verb--', '.', '...', '0.01', '0.0108', '0.02', '0.03', '0.05', '0.1', '0.10', '0.12', '0.13', '0.15']\n",
      "['yards', 'yardstick', 'year', 'year-ago', 'year-before', 'year-earlier', 'year-end', 'year-on-year', 'year-round', 'year-to-date', 'year-to-year', 'yearlong', 'yearly', 'years', 'yeast', 'yelled', 'yelling', 'yellow', 'yen', 'yes', 'yesterday', 'yet', 'yield', 'yielded', 'yielding', 'yields', 'you', 'young', 'younger', 'youngest', 'youngsters', 'your', 'yourself', 'youth', 'youthful', 'yuppie', 'yuppies', 'zero', 'zero-coupon', 'zeroing', 'zeros', 'zinc', 'zip', 'zombie', 'zone', 'zones', 'zoning', '{', '}', '']\n"
     ]
    }
   ],
   "source": [
    "#create a vocab dictionary with each word's index\n",
    "with open(\"hmm_vocab.txt\", 'r') as f:\n",
    "    voc_l = f.read().split('\\n')\n",
    "\n",
    "print(voc_l[:50])\n",
    "print(voc_l[-50:])\n",
    "\n",
    "voc_l.sort()\n",
    "vocab={}\n",
    "\n",
    "for index, word in enumerate(voc_l):\n",
    "    vocab[word]=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The\\tDT\\n',\n",
       " 'economy\\tNN\\n',\n",
       " \"'s\\tPOS\\n\",\n",
       " 'temperature\\tNN\\n',\n",
       " 'will\\tMD\\n',\n",
       " 'be\\tVB\\n',\n",
       " 'taken\\tVBN\\n',\n",
       " 'from\\tIN\\n',\n",
       " 'several\\tJJ\\n',\n",
       " 'vantage\\tNN\\n',\n",
       " 'points\\tNNS\\n',\n",
       " 'this\\tDT\\n',\n",
       " 'week\\tNN\\n',\n",
       " ',\\t,\\n',\n",
       " 'with\\tIN\\n',\n",
       " 'readings\\tNNS\\n',\n",
       " 'on\\tIN\\n',\n",
       " 'trade\\tNN\\n',\n",
       " ',\\t,\\n',\n",
       " 'output\\tNN\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test corpus\n",
    "with open(\"WSJ_24.pos\", 'r') as f:\n",
    "    y = f.readlines()\n",
    "\n",
    "y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken', 'from', 'several', '--unk--']\n",
      "34199\n"
     ]
    }
   ],
   "source": [
    "# preprocessing removes all tags from the test corpus\n",
    "_, prep = preprocess(vocab, \"test.words\")    \n",
    "print(prep[:10])\n",
    "print(len(prep))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to get training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn to creat emmission, transition and tag counts\n",
    "def create_dictionaries(training_corpus, vocab):\n",
    "    emission_counts = defaultdict(int)\n",
    "    transition_counts = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "\n",
    "    n=len(training_corpus)\n",
    "\n",
    "    prev_tag='--s--' #denotes the start state\n",
    "\n",
    "    for i in range(n):\n",
    "        if i%50000==0:\n",
    "            print('Word count: ', i)\n",
    "\n",
    "        word,tag= get_word_tag(training_corpus[i],vocab)\n",
    "\n",
    "        tag_counts[tag]+=1\n",
    "\n",
    "        emission_counts[(tag,word)]+=1\n",
    "        transition_counts[(prev_tag,tag)]+=1\n",
    "        prev_tag=tag\n",
    "\n",
    "    return emission_counts, transition_counts, tag_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count:  0\n",
      "Word count:  50000\n",
      "Word count:  100000\n",
      "Word count:  150000\n",
      "Word count:  200000\n",
      "Word count:  250000\n",
      "Word count:  300000\n",
      "Word count:  350000\n",
      "Word count:  400000\n",
      "Word count:  450000\n",
      "Word count:  500000\n",
      "Word count:  550000\n",
      "Word count:  600000\n",
      "Word count:  650000\n",
      "Word count:  700000\n",
      "Word count:  750000\n",
      "Word count:  800000\n",
      "Word count:  850000\n",
      "Word count:  900000\n",
      "Word count:  950000\n"
     ]
    }
   ],
   "source": [
    "emission_counts, transition_counts, tag_counts = create_dictionaries(training_corpus, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of POS tags (number of 'states'): 46\n",
      "View these POS tags (states)\n",
      "['#', '$', \"''\", '(', ')', ',', '--s--', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n"
     ]
    }
   ],
   "source": [
    "#states is a sorted list of all tags\n",
    "states = sorted(tag_counts.keys())\n",
    "print(f\"Number of POS tags (number of 'states'): {len(states)}\")\n",
    "print(\"View these POS tags (states)\")\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition examples: \n",
      "(('--s--', 'IN'), 5050)\n",
      "(('IN', 'DT'), 32364)\n",
      "(('DT', 'NNP'), 9044)\n",
      "\n",
      "emission examples: \n",
      "(('DT', 'any'), 721)\n",
      "(('NN', 'decrease'), 7)\n",
      "(('NN', 'insider-trading'), 5)\n",
      "\n",
      "ambiguous word example: \n",
      "('RB', 'back') 304\n",
      "('VB', 'back') 20\n",
      "('RP', 'back') 84\n",
      "('JJ', 'back') 25\n",
      "('NN', 'back') 29\n",
      "('VBP', 'back') 4\n"
     ]
    }
   ],
   "source": [
    "print(\"transition examples: \")\n",
    "for ex in list(transition_counts.items())[:3]:\n",
    "    print(ex)\n",
    "print()\n",
    "\n",
    "print(\"emission examples: \")\n",
    "for ex in list(emission_counts.items())[200:203]:\n",
    "    print (ex)\n",
    "print()\n",
    "\n",
    "print(\"ambiguous word example: \")\n",
    "for tup,cnt in emission_counts.items():\n",
    "    if tup[1] == 'back': print (tup, cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Markov Model for PoS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is the transition matrix giving probabilities of transitioning from tag i to tag j\n",
    "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
    "    n=len(tag_counts)\n",
    "    A = np.zeros((n,n))\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            key = (all_tags[i], all_tags[j])\n",
    "            count = transition_counts.get(key)\n",
    "            A[i,j]=(count+alpha)/(tag_counts[all_tags[i]]+n*alpha)\n",
    "    \n",
    "    return A\n",
    "\n",
    "#B is the emission matrix giving probabilities of tag i emitting word j\n",
    "def create_emission_matrix(alpha, tag_counts, emission_counts,vocab):\n",
    "    n = len(tag_counts)\n",
    "    m = len(vocab)\n",
    "    B = np.zeros((n,m))\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            key = (all_tags[i], vocab[j])\n",
    "            count = emission_counts.get(key)\n",
    "            B[i,j]=(count+alpha)/(tag_counts[all_tags[i]]+m*alpha)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A at row 0, col 0: 0.000007040\n",
      "A at row 3, col 1: 0.1691\n",
      "View a subset of transition matrix A\n",
      "              RBS            RP           SYM        TO            UH\n",
      "RBS  2.217069e-06  2.217069e-06  2.217069e-06  0.008870  2.217069e-06\n",
      "RP   3.756509e-07  7.516775e-04  3.756509e-07  0.051089  3.756509e-07\n",
      "SYM  1.722772e-05  1.722772e-05  1.722772e-05  0.000017  1.722772e-05\n",
      "TO   4.477336e-05  4.472863e-08  4.472863e-08  0.000090  4.477336e-05\n",
      "UH   1.030439e-05  1.030439e-05  1.030439e-05  0.061837  3.092348e-02\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.001\n",
    "A = create_transition_matrix(alpha, tag_counts, transition_counts)\n",
    "# Testing your function\n",
    "print(f\"A at row 0, col 0: {A[0,0]:.9f}\")\n",
    "print(f\"A at row 3, col 1: {A[3,1]:.4f}\")\n",
    "\n",
    "print(\"View a subset of transition matrix A\")\n",
    "A_sub = pd.DataFrame(A[30:35,30:35], index=states[30:35], columns = states[30:35] )\n",
    "print(A_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Matrix position at row 0, column 0: 0.000006032\n",
      "View Matrix position at row 3, column 1: 0.000000720\n",
      "              725      adroitly     engineers      promoted       synergy\n",
      "CD   8.201296e-05  2.732854e-08  2.732854e-08  2.732854e-08  2.732854e-08\n",
      "NN   7.521128e-09  7.521128e-09  7.521128e-09  7.521128e-09  2.257091e-05\n",
      "NNS  1.670013e-08  1.670013e-08  4.676203e-04  1.670013e-08  1.670013e-08\n",
      "VB   3.779036e-08  3.779036e-08  3.779036e-08  3.779036e-08  3.779036e-08\n",
      "RB   3.226454e-08  6.456135e-05  3.226454e-08  3.226454e-08  3.226454e-08\n",
      "RP   3.723317e-07  3.723317e-07  3.723317e-07  3.723317e-07  3.723317e-07\n"
     ]
    }
   ],
   "source": [
    "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab))\n",
    "\n",
    "print(f\"View Matrix position at row 0, column 0: {B[0,0]:.9f}\")\n",
    "print(f\"View Matrix position at row 3, column 1: {B[3,1]:.9f}\")\n",
    "\n",
    "# Try viewing emissions for a few words in a sample dataframe\n",
    "cidx  = ['725','adroitly','engineers', 'promoted', 'synergy']\n",
    "\n",
    "# Get the integer ID for each word\n",
    "cols = [vocab[a] for a in cidx]\n",
    "\n",
    "# Choose POS tags to show in a sample dataframe\n",
    "rvals =['CD','NN','NNS', 'VB','RB','RP']\n",
    "\n",
    "# For each POS tag, get the row number from the 'states' list\n",
    "rows = [states.index(a) for a in rvals]\n",
    "\n",
    "# Get the emissions for the sample of words, and the sample of POS tags\n",
    "B_sub = pd.DataFrame(B[np.ix_(rows,cols)], index=rvals, columns = cidx )\n",
    "print(B_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "from math import log\n",
    "def initialize(states, tag_counts, A, B, corpus, vocab):\n",
    "    m = len(tag_counts)\n",
    "    n = len(corpus)\n",
    "    C = np.zeros((m,n)) # best probabilities\n",
    "    D = np.zeros((m,n)) # best paths\n",
    "    s_idx = states.index(\"--s--\")\n",
    "    for i in range(m):\n",
    "        if A[s_idx,i] ==0 :\n",
    "            C[i,0]=float('-inf')\n",
    "        else:\n",
    "            C[i,0] = log(A[s_idx,i])+log(B[i,vocab[corpus[0]]])\n",
    "    \n",
    "    return C,D\n",
    "\n",
    "# C is the best probabilities matrix. C_ij gives the best probability of the entire string up till word j with tag i.\n",
    "# D is the best paths matrix. after the first column, D_ij gives the index of the tag that leads us to the best probability correspondin to C_ij. \n",
    "\n",
    "#forward step\n",
    "\n",
    "def viterbi_forward(A, B, corpus, C, D, vocab):\n",
    "    m = C.shape[0]\n",
    "    n = len(corpus)\n",
    "\n",
    "    for j in range(1,n):\n",
    "        if j%5000==0:\n",
    "            print(f'Processing {j}th word . . .')\n",
    "        for i in range(m):\n",
    "            \n",
    "            best_prob = float('-inf')\n",
    "            best_index=None\n",
    "\n",
    "            for k in range(m):\n",
    "                prob = C[k,j-1]+log(A[k,i])+log(B[i,vocab[corpus[j]]])\n",
    "                if prob>best_prob:\n",
    "                    best_prob=prob\n",
    "                    best_index=k\n",
    "\n",
    "            C[i,j]=best_prob\n",
    "            D[i,j]=best_index\n",
    "    \n",
    "    return C, D\n",
    "\n",
    "#backwards step\n",
    "\n",
    "def viterbi_backward(C, D, corpus, states):\n",
    "    t = len(corpus)\n",
    "    pred = [None]*t\n",
    "    best_prob=float('-inf')\n",
    "    best_index=None\n",
    "    for i in range(C.shape[0]):\n",
    "            if C[i,-1]>best_prob:\n",
    "                best_prob=C[i,-1]\n",
    "                best_index=i\n",
    "    pred[-1]=states[best_index]\n",
    "\n",
    "    for j in range(t-2,-1,-1):\n",
    "        best_prob=float('-inf')\n",
    "        best_index=None\n",
    "        for i in range(C.shape[0]):\n",
    "            if C[i,j+1]>best_prob:\n",
    "                best_prob=C[i,j+1]\n",
    "                best_index=i\n",
    "        pred[j]=states[int(D[best_index,j+1])]\n",
    "    \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0,0]: -22.6098\n",
      "best_paths[2,3]: 0.0000\n"
     ]
    }
   ],
   "source": [
    "C,D = initialize(states, tag_counts, A, B, prep, vocab)\n",
    "# Test the function\n",
    "print(f\"best_probs[0,0]: {C[0,0]:.4f}\") \n",
    "print(f\"best_paths[2,3]: {D[2,3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5000th word . . .\n",
      "Processing 10000th word . . .\n",
      "Processing 15000th word . . .\n",
      "Processing 20000th word . . .\n",
      "Processing 25000th word . . .\n",
      "Processing 30000th word . . .\n"
     ]
    }
   ],
   "source": [
    "# this will take a few minutes to run => processes ~ 30,000 words\n",
    "C, D = viterbi_forward(A, B, prep, C, D, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0,1]: -24.7822\n",
      "best_probs[0,4]: -49.5601\n"
     ]
    }
   ],
   "source": [
    "print(f\"best_probs[0,1]: {C[0,1]:.4f}\") \n",
    "print(f\"best_probs[0,4]: {C[0,4]:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for pred[-7:m-1] is: \n",
      " ['see', 'them', 'here', 'with', 'us', '.'] \n",
      " ['VB', 'PRP', 'RB', 'IN', 'PRP', '.'] \n",
      "\n",
      "The prediction for pred[0:8] is: \n",
      " ['DT', 'NN', 'POS', 'NN', 'MD', 'VB', 'VBN'] \n",
      " ['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken']\n"
     ]
    }
   ],
   "source": [
    "# Run and test your function\n",
    "pred = viterbi_backward(C, D, prep, states)\n",
    "m=len(pred)\n",
    "print('The prediction for pred[-7:m-1] is: \\n', prep[-7:m-1], \"\\n\", pred[-7:m-1], \"\\n\")\n",
    "print('The prediction for pred[0:8] is: \\n', pred[0:7], \"\\n\", prep[0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred,y):\n",
    "    correct=0\n",
    "    total=0\n",
    "    for prediction, true_val in zip(pred,y):\n",
    "        \n",
    "        word_tag = true_val.split()\n",
    "\n",
    "        if len(word_tag)!=2:\n",
    "            continue\n",
    "\n",
    "        word, tag = word_tag\n",
    "\n",
    "        if prediction==tag:\n",
    "            correct+=1\n",
    "        total+=1\n",
    "    \n",
    "    return correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Viterbi algorithm is 0.9528\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the Viterbi algorithm is {compute_accuracy(pred, y):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
